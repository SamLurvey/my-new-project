# Text: created by a human or by a robot?

Final project for the Building AI course

## Summary

A commonly imagined use of machine learning is the creation of text generated by a machine and not a human, including everything from scripts for television episodes to imaginary chapters of books (see: https://botnik.org/content/harry-potter.html). Although this technology remains in its infancy, as can be seen from the attached link, it has potential to increase drastically in ability in the future, potentially allowing for the creation of texts that are indistinguishable from those created by humans. This project seeks to create a machine learning algorithm that can determine whether texts are created by humans or by machines.

## Background

Machine-created text could have many negative uses in the future, including the creation of misinformation on a wide scale. Because of this, it is crucial that a method of detecting it be developed.


## How is it used?

This project would take a written text as an input, and determine the probability that it was created by a human. Since the formats for different kinds of written texts are drastically different, it would be necessary to create a different algorithm for each of them (e.g. books, play scripts, movie scripts, articles, blog posts, etc.)


## Data sources and AI methodsu
The data on human-created works would be easy to gather, as there are numerous free online sources for written texts. For example, ebooks could be gathered from project gutenberg (https://www.gutenberg.org/). Gathering machine-generated texts would be harder, however a variety of bots to generate them could be used in order to create machine-generated texts to train the algorithm on.

## Challenges

One limitation of this project is that in short texts formats, such as articles, it may be very difficult or even impossible to determine whether something was written by a human or not as the power of machine learning advances. Another challenge is the risk of overfitting, as the algorithm may overfit to the bots used to develop the machine-learning training examples and be unable to detect the works of any other bots, and as new bots with new algorithms may be undetected altogether.
